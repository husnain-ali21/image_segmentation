{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image segmentation with U_Net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOP7PKBFcGqwMtgHmLmuYgT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C20hINw5XN-X"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "torch.manual_seed(0)\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\n",
        "    size per image, plots and prints the images in an uniform grid.\n",
        "    '''\n",
        "    # image_shifted = (image_tensor + 1) / 2\\\n",
        "    image_shifted = image_tensor\n",
        "    image_unflat = image_shifted.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=4)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H41PASGYXcV1"
      },
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self , inn ) :\n",
        "        self.ContractingBlock = nn.Sequential(\n",
        "            nn.Conv2d(inn , 2*inn , kernel_size=(3,3)), nn.ReLu() ,\n",
        "            nn.Conv2d(2*inn , 2*inn , kernel_size=(3,3)) , nn.ReLu(), \n",
        "            nn.MaxPool2d()\n",
        "        )\n",
        "    def forward(self , images):\n",
        "        return self.ContractingBlock(images)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgOj0W_yZFhG"
      },
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self , inn ):\n",
        "        self.upsampling = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2 , mode = 'bilinear' , align_corners=True) , \n",
        "            nn.Conv2d(inn , inn//2 , kernel_size=(2,2)) ,nn.ReLU() , \n",
        "        )\n",
        "        \n",
        "        self.ExpandingBlock = nn.Sequential(\n",
        "            nn.Conv2d(inn , inn//2 , kernel_size=(3,3))  , nn.ReLU(),\n",
        "            nn.Conv2d(inn//2 , inn//4 , kernel_size= (3,3)) , nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def crop_features(self ,image , new_shape):\n",
        "\n",
        "        x  , y = image.shape[2] - new_shape[2]   , image.shape[3] -new_shape[3]\n",
        "        x,y= x//2 , y // 2\n",
        "        image = image[...,x:x+new_shape[2],y:y+new_shape[3]]\n",
        "\n",
        "        return image\n",
        "\n",
        "    def forward(self , image ,encoder_feature):\n",
        "        x = self.upsampling(image)\n",
        "        x = torch.cat([x , crop_features(encoder_feature)] , axis = 1)\n",
        "        x = self.ExpandingBlock(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED70JHdTcoFF"
      },
      "source": [
        "class final_head(nn.Module):\n",
        "    def __init__(self , inn , out):\n",
        "        self.map = nn.Conv2d(inn , out , kernel_size=(1,1))\n",
        "    def forward(self , x):\n",
        "        return self.map(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4qWhEQqZFQ2"
      },
      "source": [
        ""
      ]
    }
  ]
}